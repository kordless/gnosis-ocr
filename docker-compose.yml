version: '3.8'

services:
  app:
    image: gnosis-ocr:latest
    build:
      context: .
      dockerfile: Dockerfile
    
    ports:
      - "7799:7799"

    environment:
      - PORT=7799
      - CUDA_VISIBLE_DEVICES=0
      - MAX_FILE_SIZE=524288000  # 500MB with chunked streaming
      - SESSION_TIMEOUT=3600
      - LOG_LEVEL=INFO
      - MODEL_NAME=nanonets/Nanonets-OCR-s
      - STORAGE_PATH=/app/storage

      - HF_HOME=/app/cache
      - MODEL_CACHE_PATH=/app/cache
      - TRANSFORMERS_CACHE=/app/cache
      - HF_DATASETS_CACHE=/app/cache
      # Cloud environment variables (set if deploying to cloud)
      # - RUNNING_IN_CLOUD=true
      # - GCS_BUCKET_NAME=gnosis-ocr-storage
      # - MODEL_BUCKET_NAME=gnosis-ocr-models

    volumes:
      # Mount for development - hot reload (comment out for production)
      - ./app:/app/app
      # Docker volume for user data storage (persists across container restarts)
      - gnosis_ocr_storage:/app/storage
      # Mount model cache to avoid rebuilding with every code change
      - ./model-cache:/app/cache


    # Modern Docker Compose GPU support (Compose v3.8+)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7799/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s  # Increased for model loading time

    restart: unless-stopped

volumes:
  gnosis_ocr_storage:
    driver: local


